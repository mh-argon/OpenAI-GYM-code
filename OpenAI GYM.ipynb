{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0644f532",
   "metadata": {},
   "source": [
    "# Reinforcment Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bb8a20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initial State ===\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | :\u001b[43m \u001b[0m:G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#provides the basic imports and environment to use as well as print the initial state\n",
    "import gym\n",
    "env = gym.make(\"Taxi-v3\").env\n",
    "# the printing method\n",
    "print(\"=== Initial State ===\")\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1711cf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n",
      "Action Space Discrete(6)\n",
      "State Space Discrete(500)\n"
     ]
    }
   ],
   "source": [
    "# will reset the environment to a new state and print out what the state looks like\n",
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "# this prints out the action space, (which action it takes north, south ect ect) \n",
    "# actions would be 0 = south, 1 = north, 2 = east, 3 = west, 4 = pick-up, 5 = dropoff. this is between 0-5 so actionspace is 6\n",
    "# and the state space, which state of the 500 possible states it can be in\n",
    "print(\"Action Space {}\".format(env.action_space))\n",
    "print(\"State Space {}\".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bda3424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 328\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this sets the state of the current taxi based on the (row, column, position, destination)\n",
    "state = env.encode(3, 1, 2, 0)\n",
    "# prints the state\n",
    "print(\"State:\", state)\n",
    "\n",
    "# sets the environment state to the state value and renders it\n",
    "env.s = state\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32b33c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 428, -1, False)],\n",
       " 1: [(1.0, 228, -1, False)],\n",
       " 2: [(1.0, 348, -1, False)],\n",
       " 3: [(1.0, 328, -1, False)],\n",
       " 4: [(1.0, 328, -10, False)],\n",
       " 5: [(1.0, 328, -10, False)]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic reward table to showcase whats happening\n",
    "# as can be seen every position has a state and the boolean value details whether it has finished. \n",
    "# this is a dictionary using the format action:(probability, next state, reward, done)\n",
    "# pick up or drop off is the worst possible reward as there is no passenger in the taxi or in the road\n",
    "# the rest are simple moves, better to go towards a position than to stay still\n",
    "env.P[328]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "220a8b24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 5670\n",
      "Penalties incurred: 1834\n"
     ]
    }
   ],
   "source": [
    "# sets the environment to the state\n",
    "env.s = 328\n",
    "epochs = 0\n",
    "penalties, reward = 0, 0\n",
    "# used for animations not really necessary in this case\n",
    "frames = []\n",
    "# whether the sequence is finished\n",
    "done = False\n",
    "# while loop for the overall actions and states so the machine can slowly learn what its doing\n",
    "while not done:\n",
    "    # set a possible action\n",
    "    action = env.action_space.sample()\n",
    "    # set the variables basde on the aquired actions\n",
    "    state, reward, done, info = env.step(action)\n",
    "    # checks if the action is the worst possible one\n",
    "    if reward == -10:\n",
    "        penalties += 1\n",
    "    # Put each rendered frame into dict for animation\n",
    "    # again not quite necessarry for the overall idea but a useful one\n",
    "    frames.append({\n",
    "        'frame': env.render(mode='ansi'),\n",
    "        'state': state,\n",
    "        'action': action,\n",
    "        'reward': reward\n",
    "        }\n",
    "    )\n",
    "    epochs += 1  \n",
    "# prints based on the steps taken and how many penalties from making the best move, because\n",
    "# regardless the amchine takes some penalties form its moves.\n",
    "print(\"Timesteps taken: {}\".format(epochs))\n",
    "print(\"Penalties incurred: {}\".format(penalties))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fffd4a8",
   "metadata": {},
   "source": [
    "# Q-Learning in Taxi Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "993da4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting setup to determine the overall numpy value adn the q-table for the q-value\n",
    "import numpy as np\n",
    "q_table = np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd7cf0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100000\n",
      "Training finished.\n",
      "\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"Training the agent\"\"\"\n",
    "#uses the random and Ipython \n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1\n",
    "# plotting the matrix \n",
    "all_epochs = []\n",
    "all_penalties = []\n",
    "\n",
    "# the maximum aount is 100000 whereas the minimum episode is 1, loop to rin through everything\n",
    "for i in range(1, 100001):\n",
    "    state = env.reset()\n",
    "    epochs, penalties, reward, = 0, 0, 0\n",
    "    done = False\n",
    "    \n",
    "    # while this loop is not finished the computer will explore random actions or exploit the best outcome based on learned values\n",
    "    while not done:\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(q_table[state])\n",
    "            \n",
    "        #sets the next step values\n",
    "        next_state, reward, done, info = env.step(action) \n",
    "        \n",
    "        #starts and prepares the overall solve for the q-value\n",
    "        old_value = q_table[state, action]\n",
    "        next_max = np.max(q_table[next_state])\n",
    "        \n",
    "        # uses the next value by checking what it is and applying it to the prior value\n",
    "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "        q_table[state, action] = new_value\n",
    "\n",
    "        # sets the penalties for actions made\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        # sets the state to the next_state\n",
    "        state = next_state\n",
    "        epochs += 1\n",
    "        \n",
    "    # if loop does not leave a remainder of 0 clear iputut and set wait\n",
    "    if i % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Episode: {i}\")\n",
    "\n",
    "print(\"Training finished.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "668235a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.41269506,  -2.27325184,  -2.41722775,  -2.3616033 ,\n",
       "       -11.09542391, -11.21985096])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showcases what the q-value looks like now\n",
    "# the closer value to 0 the better the actual decision is\n",
    "q_table[328]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7da18d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 100 episodes:\n",
      "Average timesteps per episode: 13.23\n",
      "Average penalties per episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
    "\n",
    "# checks the overall penalties and ferformance of the agent\n",
    "total_epochs, total_penalties = 0, 0\n",
    "# based on 100 episodes \n",
    "episodes = 100\n",
    "\n",
    "# loops all in range within epsiodes, 100, and sets the state for done\n",
    "for _ in range(episodes):\n",
    "    state = env.reset()\n",
    "    epochs, penalties, reward = 0, 0, 0\n",
    "    done = False\n",
    "    \n",
    "    # while not finished will set the variables based on the actions generated\n",
    "    while not done:\n",
    "        action = np.argmax(q_table[state])\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        epochs += 1\n",
    "\n",
    "    # prepares the print valeus\n",
    "    total_penalties += penalties\n",
    "    total_epochs += epochs\n",
    "\n",
    "    #prints the values as well as the format it appears in\n",
    "print(f\"Results after {episodes} episodes:\")\n",
    "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
    "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e06fd",
   "metadata": {},
   "source": [
    "# Q-Learning in Cart-Pole Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db19c8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.185\n"
     ]
    }
   ],
   "source": [
    "# set the import libraries\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# method for running the overall episodes\n",
    "def run_episode(env, parameters):\n",
    "    observation = env.reset()\n",
    "    totalreward = 0\n",
    "    # does this 200 times\n",
    "    for _ in range(200):\n",
    "        # sets the action to 0 if the parameter observation output is less than 0, otherwise its 1\n",
    "        action = 0 if np.matmul(parameters,observation) < 0 else 1\n",
    "        # sets the observation, reward, done, infor variable to the created environment.step\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        # adds to a total reward based on the valid steps taken\n",
    "        totalreward += reward\n",
    "        #breaks the loop if complete\n",
    "        if done:\n",
    "            break\n",
    "    # returns the reward\n",
    "    return totalreward\n",
    "\n",
    "# this is the overall training method\n",
    "def train(submit):\n",
    "    # will set invironment to the carpole gym \n",
    "    env = gym.make('CartPole-v0')\n",
    "    # if values have been submitted and the sumbitted values are valid\n",
    "    if submit:\n",
    "        # will start to monitor and check the cartpole actions \n",
    "        env.monitor.start('cartpole-experiments/', force=True)\n",
    "\n",
    "    # setting counter, bestparams, bestreward\n",
    "    counter = 0\n",
    "    bestparams = None\n",
    "    bestreward = 0\n",
    "    # loops to 10000 tiems \n",
    "    for _ in range(10000):\n",
    "        # adding a counter each time\n",
    "        counter += 1\n",
    "        # sets the parameters to a random number from 0-3 and multiplying it by 2 - 1\n",
    "        parameters = np.random.rand(4) * 2 - 1\n",
    "        # sets reward to the returned epsiode value i.e what it gets for the steps\n",
    "        reward = run_episode(env,parameters)\n",
    "        # will pick the best reward from the actions taken\n",
    "        if reward > bestreward:\n",
    "            bestreward = reward\n",
    "            bestparams = parameters\n",
    "            if reward == 200:\n",
    "                break\n",
    "    # if submitted than loops the epsidoe 100 times and closes the monitor\n",
    "    if submit:\n",
    "        for _ in xrange(100):\n",
    "            run_episode(env,bestparams)\n",
    "        env.monitor.close()\n",
    "    # returns the counter value representing the amount of times something happens\n",
    "    return counter\n",
    "\n",
    "# train an agent to submit to openai gym\n",
    "# train(submit=True)\n",
    "\n",
    "# create graphs\n",
    "results = []\n",
    "for _ in range(1000):\n",
    "    results.append(train(submit=False))\n",
    "\n",
    "# sets the plot values nad what the laabels will be like, had to remove hist = 1 as it broke the overall code\n",
    "# also had to change x_range in the loops to range(\"value\") as this may have been an older codeing method\n",
    "plt.hist(results,50, facecolor='g', alpha=0.75)\n",
    "plt.xlabel('Episodes required to reach 200')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Random Search')\n",
    "plt.show()\n",
    "\n",
    "#prints the results scaled down\n",
    "print (np.sum(results) / 1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8c8bd795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172.485\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# returns the total reward from the actions taken\n",
    "def run_episode(env, parameters):\n",
    "    # sets the observation to the environments current state\n",
    "    observation = env.reset()\n",
    "    # prepares totalreward and counter\n",
    "    totalreward = 0\n",
    "    counter = 0\n",
    "    # loops to check the actions that can be taken and the rewards that are returned\n",
    "    for _ in range(200):\n",
    "        # env.render()\n",
    "        # action if parameters and observations are met, returns 0 or 1\n",
    "        action = 0 if np.matmul(parameters,observation) < 0 else 1\n",
    "        # sets the variables to the steps overall outcome\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        # sets total reward to reward after all calculations\n",
    "        totalreward += reward\n",
    "        # sets the amount of steps as coutner\n",
    "        counter += 1\n",
    "        # Break if finished \n",
    "        if done:\n",
    "            break\n",
    "    return totalreward\n",
    "\n",
    "# sets the trainign method focusing on teaching the machine\n",
    "def train(submit):\n",
    "    env = gym.make('CartPole-v0')\n",
    "    if submit:\n",
    "        env.monitor.start('cartpole-hill/', force=True)\n",
    "\n",
    "    # sets the amount of episodes per update\n",
    "    episodes_per_update = 5\n",
    "    # sets the noise scaling value\n",
    "    noise_scaling = 0.1\n",
    "    # sets the parameters ot the 0-3 * 2 - 1 value\n",
    "    parameters = np.random.rand(4) * 2 - 1\n",
    "    # prepares bestreward and counter\n",
    "    bestreward = 0\n",
    "    counter = 0\n",
    "\n",
    "    # loops a range to 2000\n",
    "    for _ in range(2000):\n",
    "        # adds counter\n",
    "        counter += 1\n",
    "        # newparams is set to the parameters and a random value with noise scaling\n",
    "        newparams = parameters + (np.random.rand(4) * 2 - 1)*noise_scaling\n",
    "        # sets reward to the returned total reward of run-episode\n",
    "        reward = run_episode(env,newparams)\n",
    "        # if the reward is greater thna the best reward than replce it with the new rwards\n",
    "        if reward > bestreward:\n",
    "            bestreward = reward\n",
    "            parameters = newparams\n",
    "            if reward == 200:\n",
    "                break\n",
    "\n",
    "    # if submitted will run a loop 100 times for the episode and the monitor will cloese\n",
    "    # returns the counter\n",
    "    if submit:\n",
    "        for _ in range(100):\n",
    "            run_episode(env,parameters)\n",
    "        env.monitor.close()\n",
    "    return counter\n",
    "\n",
    "\n",
    "# prints the amount of runs to get the overall preferred state\n",
    "r = train(submit=False)\n",
    "print (r)\n",
    "\n",
    "# create graphs\n",
    "results = []\n",
    "for _ in range(1000):\n",
    "    results.append(train(submit=False))\n",
    "\n",
    "# sets the plot values nad what the laabels will be like, had to remove hist = 1 as it broke the overall code\n",
    "# also had to change x_range in the loops to range(\"value\") as this may have been an older codeing method\n",
    "plt.hist(results,50, facecolor='g', alpha=0.75)\n",
    "plt.xlabel('Episodes required to reach 200')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Random Search')\n",
    "plt.show()\n",
    "\n",
    "#prints the results scaled down\n",
    "print (np.sum(results) / 1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abbff21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
